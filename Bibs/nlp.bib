

@article{2015.ml,
  author = {M. I. Jordan  and T. M. Mitchell },
  title = {Machine learning: Trends, perspectives, and prospects},
  journal = {Science},
  volume = {349},
  number = {6245},
  pages = {255--260},
  year = {2015},
  doi = {https://doi.org/10.1126/science.aaa8415},
}
@inproceedings{2020.ml,
  author = {Christoph Molnar and Giuseppe Casalicchio and Bernd Bischl},
  title = {Interpretable Machine Learning - {A} Brief History, State-of-the-Art and Challenges},
  booktitle = {{ECML} {PKDD} 2020 Workshops - Workshops of the European Conference on Machine Learning and Knowledge Discovery in Databases},
  volume = {1323},
  pages = {417--431},
  year = {2020},
  doi = {https://doi.org/10.1007/978-3-030-65965-3\_28},
}
@book{1984.ml.tree,
  author = {Leo Breiman and J. H. Friedman and Richard A. Olshen and C. J. Stone},
  title = {Classification and Regression Trees},
  publisher = {Wadsworth},
  year = {1984},
}
@article{2001.ml.tree.rf,
  author = {Leo Breiman},
  title = {Random Forests},
  journal = {Machine Learning},
  volume = {45},
  number = {1},
  pages = {5--32},
  year = {2001},
  doi = {https://doi.org/10.1023/A:1010933404324},
}
@article{2006.ml.tree.ert,
  author = {Pierre Geurts and Damien Ernst and Louis Wehenkel},
  title = {Extremely randomized trees},
  journal = {Machine Learning},
  volume = {63},
  number = {1},
  pages = {3--42},
  year = {2006},
  doi = {https://doi.org/10.1007/s10994-006-6226-1},
}
@article{1995.ml.svm,
  author = {Corinna Cortes and Vladimir Vapnik},
  title = {Support-Vector Networks},
  journal = {Machine Learning},
  volume = {20},
  number = {3},
  pages = {273--297},
  year = {1995},
  doi = {https://doi.org/10.1007/BF00994018},
}
@article{2011.ml.libsvm,
  author = {Chih{-}Chung Chang and Chih{-}Jen Lin},
  title = {{LIBSVM:} {A} library for support vector machines},
  journal = {ACM Transactions on Intelligent Systems and Technology},
  volume = {2},
  number = {3},
  pages = {27:1--27:27},
  year = {2011},
  doi = {https://doi.org/10.1145/1961189.1961199},
}

@book{2016.dl,
  author = {Ian Goodfellow, Yoshua Bengio, Aaron Courville},
  title = {Deep Learning},
  year = {2016},
  publisher = {MIT Press}
}
@book{2018.dl,
  title={The deep learning revolution},
  author={Sejnowski, Terrence J},
  year={2018},
  publisher={MIT press}
}
@article{2020.dl.interprety,
  author = {Mengnan Du and Ninghao Liu and Xia Hu},
  title = {Techniques for interpretable machine learning},
  journal = {Communications of the ACM},
  volume = {63},
  number = {1},
  pages = {68--77},
  year = {2020},
  doi = {https://doi.org/10.1145/3359786},
}
@article{2019.dl.interprety,
  author = {Riccardo Guidotti and Anna Monreale and Salvatore Ruggieri and Franco Turini and Fosca Giannotti and Dino Pedreschi},
  title = {A Survey of Methods for Explaining Black Box Models},
  journal = {ACM Computing Surveys},
  volume = {51},
  number = {5},
  pages = {93:1--93:42},
  year = {2019},
  doi = {https://doi.org/10.1145/3236009},
}
@article{2023.dl.gcrf,
  title={Gaussian conditional random fields for classification},
  journal={Expert Systems with Applications},
  volume={212},
  pages={118728},
  year={2023},
  doi={https://doi.org/10.1016/j.eswa.2022.118728},
  author={Andrija Petrović and Mladen Nikolić and Miloš Jovanović and Boris Delibašić},
}
@book{2009.dl.lda,
  author = {Bengio, Yoshua},
  title = {Learning Deep Architectures for AI},
  year = {2009},
  doi = {https://doi.org/10.1561/2200000006}
}
@book{2016.dl.asr,
  title = {Automatic speech recognition},
  author = {Yu, Dong and Deng, Lin},
  volume = {1},
  year = {2016},
  publisher = {Berlin: Springer}
}
@article{2007.dl.asr,
  author = {Mohamed Benzeghiba and Renato de Mori and Olivier Deroo and St{\'{e}}phane Dupont and Teodora Erbes and Denis Jouvet and Luciano Fissore and Pietro Laface and Alfred Mertins and Christophe Ris and Richard Rose and Vivek Tyagi and Christian Wellekens},
  title = {Automatic speech recognition and speech variability: {A} review},
  journal = {Speech Communication},
  volume = {49},
  number = {10-11},
  pages = {763--786},
  year = {2007},
  doi = {https://doi.org/10.1016/j.specom.2007.02.006},
}

@inproceedings{2023.nlp.survey.da,
  title={Knowledge-augmented methods for natural language processing},
  author={Zhu, Chenguang and Xu, Yichong and Ren, Xiang and Lin, Bill Yuchen and Jiang, Meng and Yu, Wenhao},
  booktitle={Proceedings of the Sixteenth ACM International Conference on Web Search and Data Mining},
  pages={1228--1231},
  year={2023}
}
@inproceedings{2018.nlp.appl.nmt,
  author = {Jiatao Gu and Yong Wang and Kyunghyun Cho and Victor O. K. Li},
  title = {Search Engine Guided Neural Machine Translation},
  booktitle = {Proceedings of the Thirty-Second {AAAI} Conference on Artificial Intelligence, the 30th innovative Applications of Artificial Intelligence, and the 8th {AAAI} Symposium on Educational Advances in Artificial Intelligence},
  pages = {5133--5140},
  year = {2018},
  doi = {https://doi.org/10.1609/aaai.v32i1.12013},
}


## NLP Basic Techniques
@inproceedings{2022.nlp.wmd,
  author = {Ryoma Sato and Makoto Yamada and Hisashi Kashima},
  title  = {Re-evaluating Word Mover's Distance},
  booktitle = {International Conference on Machine Learning},
  volume = {162},
  pages = {19231--19249},
  year = {2022},
}
@article{2008.nlp.tsne,
  title   = {Visualizing data using t-SNE.},
  author  = {Van der Maaten, Laurens and Hinton, Geoffrey},
  journal = {Journal of machine learning research},
  volume  = {9},
  number  = {11},
  year    = {2008}
}
@inproceedings{2014.nlp.corenlp,
  author = {Christopher D. Manning and Mihai Surdeanu and John Bauer and Jenny Rose Finkel and Steven Bethard and David McClosky},
  title = {The Stanford CoreNLP Natural Language Processing Toolkit},
  booktitle = {Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics},
  pages = {55--60},
  year = {2014},
  doi = {https://doi.org/10.3115/v1/p14-5010},
}
@inproceedings{2013.nlp.word2vec,
  author = {Mikolov, Tomas and Sutskever, Ilya and Chen, Kai and Corrado, Greg S and Dean, Jeff},
  booktitle = {Advances in Neural Information Processing Systems},
  pages = {},
  title = {Distributed Representations of Words and Phrases and their Compositionality},
  volume = {26},
  year = {2013}
}
@article{2009.nlp.bm25,
  title = {The probabilistic relevance framework: BM25 and beyond},
  author = {Robertson, Stephen and Zaragoza, Hugo and others},
  journal = {Foundations and Trends{\textregistered} in Information Retrieval},
  volume = {3},
  number = {4},
  pages = {333--389},
  year = {2009},
}
@inproceedings{2016.nlp.bpe,
  title={Neural Machine Translation of Rare Words with Subword Units},
  author={Sennrich, Rico and Haddow, Barry and Birch, Alexandra},
  booktitle={Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics},
  pages={1715--1725},
  year={2016}
}
@inproceedings{2019.nlp.sbert,
  title = "Sentence-{BERT}: Sentence Embeddings using {S}iamese {BERT}-Networks",
  author = "Reimers, Nils and Gurevych, Iryna",
  booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing",
  year = "2019",
  doi = "https://doi.org/10.18653/v1/D19-1410",
  pages = "3982--3992",
}
@article{2022.nlp.attn.survey,
  title={Attention mechanisms in computer vision: A survey},
  author={Guo, Meng-Hao and Xu, Tian-Xing and Liu, Jiang-Jiang and Liu, Zheng-Ning and Jiang, Peng-Tao and Mu, Tai-Jiang and Zhang, Song-Hai and Martin, Ralph R and Cheng, Ming-Ming and Hu, Shi-Min},
  journal={Computational visual media},
  volume={8},
  number={3},
  pages={331--368},
  year={2022},
}




## NLP Advanced Methods


@article{2020.nlp.gan,
  author = {Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  title = {Generative adversarial networks},
  year = {2020},
  volume = {63},
  number = {11},
  doi = {https://doi.org/10.1145/3422622},
  journal = {Communications of the ACM},
  pages = {139–144},
  numpages = {6}
}

## Pre-trained Language Models
@inproceedings{2019.nlp.plm.knowledge,
  author = {Fabio Petroni and Tim Rockt{\"{a}}schel and Sebastian Riedel and Patrick S. H. Lewis and Anton Bakhtin and Yuxiang Wu and Alexander H. Miller},
  title = {Language Models as Knowledge Bases?},
  booktitle = {Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing},
  pages = {2463--2473},
  year = {2019},
  doi = {https://doi.org/10.18653/v1/D19-1250},
}
@inproceedings{2020.nlp.plm.knowledge,
  author = {Adam Roberts and Colin Raffel and Noam Shazeer},
  title = {How Much Knowledge Can You Pack Into the Parameters of a Language Model?},
  booktitle = {Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing},
  pages = {5418--5426},
  year = {2020},
  doi = {https://doi.org/10.18653/v1/2020.emnlp-main.437},
}
@inproceedings{2017.nlp.plm.opt.sgdr,
  title={{SGDR}: Stochastic Gradient Descent with Warm Restarts},
  author={Ilya Loshchilov and Frank Hutter},
  booktitle={International Conference on Learning Representations},
  year={2017},
}
@inproceedings{2019.nlp.plm.opt.adamw,
  author={Ilya Loshchilov and Frank Hutter},
  title={Decoupled Weight Decay Regularization},
  booktitle={7th International Conference on Learning Representations},
  year={2019},
}
@article{2016.nlp.plm.ln,
  author = {Lei Jimmy Ba and Jamie Ryan Kiros and Geoffrey E. Hinton},
  title = {Layer Normalization},
  journal = {arXiv preprint arXiv:1607.06450},
  volume = {},
  year = {2016},
}
@inproceedings{2019.nlp.plm.adamw,
  author = {Ilya Loshchilov and Frank Hutter},
  title = {Decoupled Weight Decay Regularization},
  booktitle = {7th International Conference on Learning Representations},
  year = {2019},
}
@article{2024.nlp.plm.peft,
  title={Parameter Efficient Fine Tuning: A Comprehensive Analysis Across Applications},
  author={Balne, Charith Chandra Sai and Bhaduri, Sreyoshi and Roy, Tamoghna and Jain, Vinija and Chadha, Aman},
  journal={arXiv preprint arXiv:2404.13506},
  year={2024}
}
@inproceedings{2021.nlp.plm.peft.prefix-tuning,
  title="Prefix-Tuning: Optimizing Continuous Prompts for Generation",
  author="Li, Xiang Lisa  and Liang, Percy",
  booktitle="Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing",
  year="2021",
  doi="https://doi.org/10.18653/v1/2021.acl-long.353",
  pages="4582--4597",
}
@inproceedings{2020.nlp.plm.peft.adapterhub,
  title="{A}dapter{H}ub: A Framework for Adapting Transformers",
  author={Pfeiffer, Jonas and R{\"u}ckl{\'e}, Andreas and Poth, Clifton and Kamath, Aishwarya and Vuli{\'c}, Ivan and Ruder, Sebastian and Cho, Kyunghyun and Gurevych, Iryna},
  booktitle="Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing",
  year="2020",
  doi="https://doi.org/10.18653/v1/2020.emnlp-demos.7",
  pages="46--54",
}
@inproceedings{2021.nlp.plm.peft.lora,
  title={Lo{RA}: Low-Rank Adaptation of Large Language Models},
  author={Edward J Hu and yelong shen and Phillip Wallis and Zeyuan Allen-Zhu and Yuanzhi Li and Shean Wang and Lu Wang and Weizhu Chen},
  booktitle={International Conference on Learning Representations},
  year={2022},
}
# Transformer
@inproceedings{2017.nlp.plm.transformer,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  booktitle={Proceedings of the 31st International Conference on Neural Information Processing Systems},
  pages={6000--6010},
  year={2017},
}
@inproceedings{2019.nlp.plm.adamw,
  title={Decoupled Weight Decay Regularization},
  author={Ilya Loshchilov and Frank Hutter},
  booktitle={7th International Conference on Learning Representations},
  year={2019},
}

# PLM Technique
@inproceedings{2023.nlp.plm.mlm,
  title={Should You Mask 15\% in Masked Language Modeling?},
  author={Wettig, Alexander and Gao, Tianyu and Zhong, Zexuan and Chen, Danqi},
  booktitle={Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics},
  year={2023},
  pages={2985--3000},
}
@inproceedings{2022.nlp.plm.mlm,
  title={Contextual Representation Learning beyond Masked Language Modeling},
  author={Fu, Zhiyi and Zhou, Wangchunshu and Xu, Jingjing and Zhou, Hao and Li, Lei},
  booktitle={Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics},
  year={2022},
  pages={2701--2714},
}
@inproceedings{2023.nlp.plm.align,
  author = {Bao, Keqin and Zhang, Jizhi and Zhang, Yang and Wang, Wenjie and Feng, Fuli and He, Xiangnan},
  title = {TALLRec: An Effective and Efficient Tuning Framework to Align Large Language Model with Recommendation},
  year = {2023},
  doi= {https://doi.org/10.1145/3604915.3608857},
  booktitle = {Proceedings of the 17th ACM Conference on Recommender Systems},
  pages = {1007–1014},
  numpages = {8}
}

## Pre-trained Language Models
@article{2020.nlp.plm.survey,
  title={Pre-trained models for natural language processing: A survey},
  author={Qiu, Xipeng and Sun, Tianxiang and Xu, Yige and Shao, Yunfan and Dai, Ning and Huang, Xuanjing},
  journal={Science China Technological Sciences},
  volume={63},
  number={10},
  pages={1872--1897},
  year={2020},
}
@article{2023.nlp.plm.survey,
  author = {Min, Bonan and Ross, Hayley and Sulem, Elior and Veyseh, Amir Pouran Ben and Nguyen, Thien Huu and Sainz, Oscar and Agirre, Eneko and Heintz, Ilana and Roth, Dan},
  title = {Recent Advances in Natural Language Processing via Large Pre-trained Language Models: A Survey},
  year = {2023},
  volume = {56},
  number = {2},
  doi = {https://doi.org/10.1145/3605943},
  journal = {ACM Computing Surveys},
  pages={1--40},
}
@article{2024.nlp.plm.survey,
  author = {Linmei Hu and Zeyi Liu and Ziwang Zhao and Lei Hou and Liqiang Nie and Juanzi Li},
  title = {A Survey of Knowledge Enhanced Pre-Trained Language Models},
  journal = {IEEE Transactions on Knowledge and Data Engineering},
  volume = {36},
  number = {4},
  pages = {1413--1430},
  year = {2024},
  doi = {https://doi.org/10.1109/TKDE.2023.3310002},
}

# Pre-train Techniques
@inproceedings{2019.nlp.plm.cloze,
  author = {Alexei Baevski and Sergey Edunov and Yinhan Liu and Luke Zettlemoyer and Michael Auli},
  title = {Cloze-driven Pretraining of Self-attention Networks},
  booktitle = {Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing},
  pages = {5359--5368},
  year = {2019},
  doi = {https://doi.org/10.18653/v1/D19-1539},
}


@inproceedings{2019.nlp.plm.bert,
  title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  booktitle={Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics},
  year={2019},
  pages={4171--4186},
  doi={https://doi.org/10.18653/v1/N19-1423}
}
@inproceedings{2019.nlp.plm.xlnet,
  author = {Zhilin Yang and Zihang Dai and Yiming Yang and Jaime G. Carbonell and Ruslan Salakhutdinov and Quoc V. Le},
  title = {XLNet: Generalized Autoregressive Pretraining for Language Understanding},
  booktitle = {Advances in Neural Information Processing Systems},
  pages = {5754--5764},
  volume = {32},
  year = {2019},
}
@inproceedings{2020.nlp.plm.bart,
  title={BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension},
  author={Lewis, Mike and Liu, Yinhan and Goyal, Naman and Ghazvininejad, Marjan and Mohamed, Abdelrahman and Levy, Omer and Stoyanov, Veselin and Zettlemoyer, Luke},
  booktitle={Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
  year={2020},
  pages={7871--7880},
  doi={https://doi.org/10.18653/v1/2020.acl-main.703}
}
@article{2019.nlp.plm.roberta,
  title={Roberta: A robustly optimized bert pretraining approach},
  author={Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
  journal={arXiv preprint arXiv:1907.11692},
  year={2019},
}
@article{2020.nlp.plm.t5,
  author={Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu},
  title={Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer},
  journal={Journal of Machine Learning Research},
  year={2020},
  volume={21},
  number={140},
  pages={1--67},
  url={http://jmlr.org/papers/v21/20-074.html}
}
@inproceedings{2020.nlp.plm.gpt3,
 author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel and Wu, Jeffrey and Winter, Clemens and Hesse, Chris and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
 booktitle={Advances in Neural Information Processing Systems},
 pages={1877--1901},
 title={Language Models are Few-Shot Learners},
 volume={33},
 year={2020}
}


## Large Language Models
@article{2020.nlp.llm.gpt3,
  title = {Language models are few-shot learners},
  author = {Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal = {Advances in neural information processing systems},
  volume = {33},
  pages = {1877--1901},
  year = {2020}
}
@article{2023.llm.survey,
  title={A survey of large language models},
  author={Zhao, Wayne Xin and Zhou, Kun and Li, Junyi and Tang, Tianyi and Wang, Xiaolei and Hou, Yupeng and Min, Yingqian and Zhang, Beichen and Zhang, Junjie and Dong, Zican and others},
  journal={arXiv preprint arXiv:2303.18223},
  year={2023}
}
@article{2024.graph.llm.survey,
  author = {Bowen Jin and Gang Liu and Chi Han and Meng Jiang and Heng Ji and Jiawei Han},
  title = {Large Language Models on Graphs: {A} Comprehensive Survey},
  journal = {IEEE Transactions on Knowledge and Data Engineering},
  volume = {36},
  number = {12},
  pages = {8622--8642},
  year = {2024},
  doi = {https://doi.org/10.1109/TKDE.2024.3469578},
}
@inproceedings{2024.rag.llm.survey,
  author = {Wenqi Fan and Yujuan Ding and Liangbo Ning and Shijie Wang and Hengyun Li and Dawei Yin and Tat{-}Seng Chua and Qing Li},
  title = {A Survey on {RAG} Meeting LLMs: Towards Retrieval-Augmented Large Language Models},
  booktitle = {Proceedings of the 30th {ACM} {SIGKDD} Conference on Knowledge Discovery and Data Mining},
  pages = {6491--6501},
  year = {2024},
  doi = {https://doi.org/10.1145/3637528.3671470},
}
@article{2024.nlp.llm.survey,
  author = {Libo Qin and Qiguang Chen and Xiachong Feng and Yang Wu and Yongheng Zhang and Yinghui Li and Min Li and Wanxiang Che and Philip S. Yu},
  title = {Large Language Models Meet {NLP:} {A} Survey},
  journal={arXiv preprint arXiv:2405.12819},
  year = {2024},
  doi = {https://doi.org/10.48550/arXiv.2405.12819},
}
@inproceedings{2024.nlp.llm.conflict,
  author = {Rongwu Xu and Zehan Qi and Zhijiang Guo and Cunxiang Wang and Hongru Wang and Yue Zhang and Wei Xu},
  title = {Knowledge Conflicts for LLMs: {A} Survey},
  booktitle = {Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing},
  pages = {8541--8565},
  year = {2024},
  doi = {https://doi.org/10.18653/v1/2024.emnlp-main.486},
}
@article{2024.nlp.llm.hugginggpt,
  title={Hugginggpt: Solving ai tasks with chatgpt and its friends in hugging face},
  author={Shen, Yongliang and Song, Kaitao and Tan, Xu and Li, Dongsheng and Lu, Weiming and Zhuang, Yueting},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}
@inproceedings{2022.llm.instructgpt,
  author = {Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and Schulman, John and Hilton, Jacob and Kelton, Fraser and Miller, Luke and Simens, Maddie and Askell, Amanda and Welinder, Peter and Christiano, Paul F and Leike, Jan and Lowe, Ryan},
  booktitle = {Advances in Neural Information Processing Systems},
  pages = {27730--27744},
  title = {Training language models to follow instructions with human feedback},
  volume = {35},
  year = {2022}
}


## LLM.CoT
@article{2022.llm.icl.survey,
  title={A survey on in-context learning},
  author={Dong, Qingxiu and Li, Lei and Dai, Damai and Zheng, Ce and Wu, Zhiyong and Chang, Baobao and Sun, Xu and Xu, Jingjing and Sui, Zhifang},
  journal={arXiv preprint arXiv:2301.00234},
  year={2022}
}
@article{2024.llm.icl.survey,
  title={In-context Learning with Retrieved Demonstrations for Language Models: A Survey},
  author={Man Luo and Xin Xu and Yue Liu and Panupong Pasupat and Mehran Kazemi},
  journal={Transactions on Machine Learning Research},
  year={2024},
}
@inproceedings{2022.llm.prompt.cot,
  author = {Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and ichter, brian and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny},
  booktitle = {Advances in Neural Information Processing Systems},
  editor = {S. Koyejo and S. Mohamed and A. Agarwal and D. Belgrave and K. Cho and A. Oh},
  pages = {24824--24837},
  title = {Chain-of-Thought Prompting Elicits Reasoning in Large Language Models},
  volume = {35},
  year = {2022}
}
@inproceedings{2023.llm.prompt.l2mp,
  author= {Denny Zhou and Nathanael Sch{\"{a}}rli and Le Hou and Jason Wei and Nathan Scales and Xuezhi Wang and Dale Schuurmans and Claire Cui and Olivier Bousquet and Quoc V. Le and Ed H. Chi},
  title= {Least-to-Most Prompting Enables Complex Reasoning in Large Language Models},
  booktitle= {The Eleventh International Conference on Learning Representations},
  year= {2023},
}
@inproceedings{2023.llm.prompt.autocot,
  author={Zhuosheng Zhang and Aston Zhang and Mu Li and Alex Smola},
  title={Automatic Chain of Thought Prompting in Large Language Models},
  booktitle={The Eleventh International Conference on Learning Representations},
  year= {2023},
}
@article{2023.llm.prompt.icl.ids,
  author= {Chengwei Qin and Aston Zhang and Anirudh Dagar and Wenming Ye},
  title= {In-Context Learning with Iterative Demonstration Selection},
  year= {2023},
  journal={arXiv preprint arXiv.2310.09881},
  doi= {https://doi.org/10.48550/arXiv.2310.09881},
}
@inproceedings{2022.llm.prompt.icl.demo,
    title = "Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?",
    author = "Min, Sewon and Lyu, Xinxi and Holtzman, Ari and Artetxe, Mikel and Lewis, Mike and Hajishirzi, Hannaneh and Zettlemoyer, Luke",
    booktitle = "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing",
    year = "2022",
    doi = "10.18653/v1/2022.emnlp-main.759",
    pages = "11048--11064",
}
@inproceedings{2022.llm.prompt.icl.retdemo,
    title = "Learning To Retrieve Prompts for In-Context Learning",
    author = "Rubin, Ohad and Herzig, Jonathan  and Berant, Jonathan",
    booktitle = "Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics",
    doi="10.18653/v1/2022.naacl-main.191",
    pages="2655--2671",
    year = "2022",
    doi="10.18653/v1/2022.naacl-main.191"
}
@inproceedings{2023.llm.prompt.selfcot,
  author= {Xuezhi Wang and Jason Wei and Dale Schuurmans and Quoc V. Le and Ed H. Chi and Sharan Narang and Aakanksha Chowdhery and Denny Zhou},
  title= {Self-Consistency Improves Chain of Thought Reasoning in Language Models},
  booktitle= {The Eleventh International Conference on Learning Representations},
  year= {2023},
}
@inproceedings{2023.llm.prompt.tot,
  author={Shunyu Yao and Dian Yu and Jeffrey Zhao and Izhak Shafran and Tom Griffiths and Yuan Cao and Karthik Narasimhan},
  title={Tree of Thoughts: Deliberate Problem Solving with Large Language Models},
  booktitle={Advances in Neural Information Processing Systems},
  year= {2023},
}
@article{2022.llm.prompt.icl.pdd,
  title={Few-Shot Natural Language Inference Generation with PDD: Prompt and Dynamic Demonstration},
  author={Li, Kaijian and Gong, Shansan and Zhu, Kenny Q},
  journal={arXiv preprint arXiv:2205.10593},
  year={2022}
}
@article{2023.llm.prompt.icl.mde,
  title={In-context learning with many demonstration examples},
  author={Li, Mukai and Gong, Shansan and Feng, Jiangtao and Xu, Yiheng and Zhang, Jun and Wu, Zhiyong and Kong, Lingpeng},
  journal={arXiv preprint arXiv:2302.04931},
  year={2023}
}
@article{2022.llm.prompt.icl.gpt,
  title={What Makes Good In-Context Examples for GPT-3?},
  author={Liu, Jiachang and Shen, Dinghan and Zhang, Yizhe and Dolan, Bill and Carin, Lawrence and Chen, Weizhu},
  journal={DeeLIO 2022},
  pages={100},
  year={2022}
}
@inproceedings{2022.llm.prompt.icl.rp,
  title={Learning To Retrieve Prompts for In-Context Learning},
  author={Rubin, Ohad and Herzig, Jonathan and Berant, Jonathan},
  booktitle={Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics},
  pages={2655--2671},
  year={2022}
}
@article{2023.llm.prompt.cot.ap,
  title={Active prompting with chain-of-thought for large language models},
  author={Diao, Shizhe and Wang, Pengcheng and Lin, Yong and Zhang, Tong},
  journal={arXiv preprint arXiv:2302.12246},
  year={2023}
}
@inproceedings{2023.llm.prompt.icl.dsp,
  author= {Zekun Li and Baolin Peng and Pengcheng He and Michel Galley and Jianfeng Gao and Xifeng Yan},
  title= {Guiding Large Language Models via Directional Stimulus Prompting},
  booktitle= {Advances in Neural Information Processing Systems},
  year= {2023},
}
@inproceedings{2022.llm.prompt.icl.ibi,
  author= {Sang Michael Xie and Aditi Raghunathan and Percy Liang and Tengyu Ma},
  title= {An Explanation of In-context Learning as Implicit Bayesian Inference},
  booktitle= {The Tenth International Conference on Learning Representations},
  year= {2022},
}



## Applications
@inproceedings{2022.llm.appl.ner,
  author={Dong{-}Ho Lee and Akshen Kadakia and Kangmin Tan and Mahak Agarwal and Xinyu Feng and Takashi Shibuya and Ryosuke Mitani and Toshiyuki Sekiya and Jay Pujara and Xiang Ren},
  title={Good Examples Make {A} Faster Learner: Simple Demonstration-based Learning for Low-resource {NER}},
  booktitle={Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics},
  pages={2687--2700},
  year={2022},
  doi={https://doi.org/10.18653/v1/2022.acl-long.192},
}
@inproceedings{2022.llm.appl.cr,
  author= {Jiacheng Liu and Alisa Liu and Ximing Lu and Sean Welleck and Peter West and Ronan Le Bras and Yejin Choi and Hannaneh Hajishirzi},
  title={Generated Knowledge Prompting for Commonsense Reasoning},
  booktitle={Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics},
  pages={3154--3169},
  year={2022},
  url={https://doi.org/10.18653/v1/2022.acl-long.225},
}
@article{2023.llm.appl.art,
  title={Art: Automatic multi-step reasoning and tool-use for large language models},
  author={Paranjape, Bhargavi and Lundberg, Scott and Singh, Sameer and Hajishirzi, Hannaneh and Zettlemoyer, Luke and Ribeiro, Marco Tulio},
  journal={arXiv preprint arXiv:2303.09014},
  year={2023}
}